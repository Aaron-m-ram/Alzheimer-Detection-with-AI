{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function preprocesses the image by reading in the image apply grayscale make all the sizes the same and \n",
    "def preprocess_image(file_path, img_size):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) # Grayscale will even the playing field if we start getting different types of images. If the images color is a factor we can take out grayscale\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float')/255.0 # Make the pixels become float and normalize to 0-1 for normalization\n",
    "    return img\n",
    "\n",
    "\n",
    "target_size =(224, 224)\n",
    "\n",
    "# This function will pull from the directory and all subdirectory for the image and give it a label to the directory it is in\n",
    "def load_images_from_directory(directory, target_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    # Iterates through all subdirectories\n",
    "    for subdir in os.listdir(directory):\n",
    "        label = subdir #Make the subdirectory name be a label\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "\n",
    "        # Checks if the object it is looking at is a directory and if it is go into the directory and get all the files and preprocess them\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for image in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, image)\n",
    "\n",
    "                image = preprocess_image(file_path, target_size)\n",
    "\n",
    "                # Append to the arrays after preprocessing\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Image shape: (5121, 224, 224)\n",
      "Labels shape: (5121,)\n",
      "\n",
      "Test\n",
      "Image shape: (1279, 224, 224)\n",
      "Labels shape: (1279,)\n"
     ]
    }
   ],
   "source": [
    "# import sys # for debugging \n",
    "\n",
    "# Define the directory paths for the training and test datasets\n",
    "train_dir = \"./Alzheimer_s Dataset/train\"\n",
    "test_dir = \"./Alzheimer_s Dataset/test\"\n",
    "\n",
    "# Load images and labels from the training directory\n",
    "alz_images_train, alz_labels_train = load_images_from_directory(train_dir)\n",
    "\n",
    "# Load images and labels from the test directory\n",
    "alz_images_test, alz_labels_test = load_images_from_directory(test_dir)\n",
    "\n",
    "# Print information about the training dataset\n",
    "print(\"Train\")\n",
    "print('Image shape:', alz_images_train.shape)\n",
    "print('Labels shape:', alz_labels_train.shape)\n",
    "\n",
    "# Print information about the test dataset\n",
    "print(\"\\nTest\")\n",
    "print('Image shape:', alz_images_test.shape)\n",
    "print('Labels shape:', alz_labels_test.shape)\n",
    "\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize) # for debugging\n",
    "\n",
    "# print('Image train:', alz_images_train) # for debugging\n",
    "\n",
    "# The output of the shape follows this\n",
    "#  (X, X1, X2)\n",
    "# X is the number of pictures in the array   \n",
    "# X1 is the number of rows for a single picture (should be 224 since that is the scale)\n",
    "# X2 is the number of columns in each picture  (should be 224 since that is the scale)\n",
    "#  *Scale can be change to 207 since that is how the data is processed. \n",
    "# \n",
    "# When pull out the full array, you see alot of 0 at the start and end and that is because of the black around the brain\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Aaron's Algorithm </h1>\n",
    "CNN GCNN or similar neural networks that can be adjusted in between each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 1 #grayscale cause it to be only 1 channel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# model1 = Sequential([\n",
    "#     Conv2D(32, (3,3), activation='relu', input_shape=(img_height))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Jay's Algorthm</h1>\n",
    "SVM and KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Geoffrey's Algorithm</h1>\n",
    "Random Forest and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
