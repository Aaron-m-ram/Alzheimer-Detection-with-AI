{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys # for debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # This function preprocesses the image by reading in the image apply grayscale make all the sizes the same and \n",
    "# def preprocess_image(file_path, img_size):\n",
    "#     img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) # Grayscale will even the playing field if we start getting different types of images. If the images color is a factor we can take out grayscale\n",
    "#     img = cv2.resize(img, img_size)\n",
    "#     img = img.astype('float')/255.0 # Make the pixels become float and normalize to 0-1 for normalization\n",
    "#     return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This function preprocesses the image by reading in the image apply grayscale make all the sizes the same and \n",
    "def preprocess_image(file_path, img_size):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) # Grayscale will even the playing field if we start getting different types of images. If the images color is a factor we can take out grayscale\n",
    "    \n",
    "    # Thresholding to remove black background\n",
    "    _, binary_image = cv2.threshold(img, 10, 255, cv2.THRESH_BINARY)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_image, connectivity=8)\n",
    "    largest_component_label = np.argmax(stats[1:, cv2.CC_STAT_AREA]) + 1\n",
    "    brain_mask = (labels == largest_component_label).astype(np.uint8) * 255\n",
    "    x, y, w, h = cv2.boundingRect(brain_mask)\n",
    "    img = img[y:y+h, x:x+w]\n",
    "    \n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float')/255.0 # Make the pixels become float and normalize to 0-1 for normalization\n",
    "    return img\n",
    "\n",
    "\n",
    "target_size =(224, 224)\n",
    "\n",
    "# This function will pull from the directory and all subdirectory for the image and give it a label to the directory it is in\n",
    "def load_images_from_directory(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    # Iterates through all subdirectories\n",
    "    for subdir in os.listdir(directory):\n",
    "        label = subdir #Make the subdirectory name be a label\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "\n",
    "        # Checks if the object it is looking at is a directory and if it is go into the directory and get all the files and preprocess them\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for image in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, image)\n",
    "\n",
    "                image = preprocess_image(file_path, target_size)\n",
    "\n",
    "                # Append to the arrays after preprocessing\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Image shape: (5121, 224, 224)\n",
      "Labels shape: (5121,)\n",
      "\n",
      "Test\n",
      "Image shape: (1279, 224, 224)\n",
      "Labels shape: (1279,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the directory paths for the training and test datasets\n",
    "train_dir = \"./Alzheimer_s Dataset/train\"\n",
    "test_dir = \"./Alzheimer_s Dataset/test\"\n",
    "# single_test_dir = \"./Alzheimer_s Dataset/single_test\"\n",
    "\n",
    "# Load images and labels from the training directory\n",
    "alz_images_train, alz_labels_train = load_images_from_directory(train_dir)\n",
    "\n",
    "# Load images and labels from the test directory\n",
    "alz_images_test, alz_labels_test = load_images_from_directory(test_dir)\n",
    "\n",
    "# alz_single_images_test, alz_single_labels_test = load_images_from_directory(single_test_dir)\n",
    "\n",
    "# Print information about the training dataset\n",
    "print(\"Train\")\n",
    "print('Image shape:', alz_images_train.shape)\n",
    "print('Labels shape:', alz_labels_train.shape)\n",
    "\n",
    "# Print information about the test dataset\n",
    "print(\"\\nTest\")\n",
    "print('Image shape:', alz_images_test.shape)\n",
    "print('Labels shape:', alz_labels_test.shape)\n",
    "\n",
    "\n",
    "# print(\"\\nSingle Test\")\n",
    "# print('Image shape:', alz_single_images_test.shape)\n",
    "# print('Labels shape:', alz_single_labels_test.shape)\n",
    "\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize) # for debugging\n",
    "\n",
    "# print('Image train:', alz_single_images_test) # for debugging\n",
    "\n",
    "# The output of the shape follows this\n",
    "#  (X, X1, X2)\n",
    "# X is the number of pictures in the array   \n",
    "# X1 is the number of rows for a single picture (should be 224 since that is the scale)\n",
    "# X2 is the number of columns in each picture  (should be 224 since that is the scale)\n",
    "#  *Scale can be change to 207 since that is how the data is processed. \n",
    "# \n",
    "# When pull out the full array, you see alot of 0 at the start and end and that is because of the black around the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape (one-hot encoded): (5121, 4)\n",
      "Testing labels shape (one-hot encoded): (1279, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "alz_labels_train_encoded = label_encoder.fit_transform(alz_labels_train)\n",
    "alz_labels_test_encoded = label_encoder.fit_transform(alz_labels_test)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "alz_labels_train_onehot = tf.keras.utils.to_categorical(alz_labels_train_encoded, num_classes)\n",
    "alz_labels_test_onehot = tf.keras.utils.to_categorical(alz_labels_test_encoded, num_classes)\n",
    "\n",
    "#np.set_printoptions(threshold=sys.maxsize) # for debugging\n",
    "#print(alz_labels_train_onehot)\n",
    "\n",
    "print(\"Training labels shape (one-hot encoded):\", alz_labels_train_onehot.shape)\n",
    "print(\"Testing labels shape (one-hot encoded):\", alz_labels_test_onehot.shape)\n",
    "\n",
    "# print('Image train:', alz_images_train) # for debugging\n",
    "\n",
    "\n",
    "# 0 = MildDemented\n",
    "# 1 = ModerateDemented\n",
    "# 2 = NonDemented\n",
    "# 3 = VeryMildDemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = target_size[1]\n",
    "img_width = target_size[0]\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>GCN</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 36.8 MiB for an array with shape (32, 224, 224, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduced_features\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Extract features from training and test images\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m train_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43malz_images_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m test_features \u001b[38;5;241m=\u001b[39m extract_features(alz_images_test)\n",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(images, batch_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m end_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size, num_images)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Convert grayscale images to RGB by stacking them along the third axis\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m batch_images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Preprocess images and extract features\u001b[39;00m\n\u001b[0;32m     22\u001b[0m preprocessed_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mapplications\u001b[38;5;241m.\u001b[39mmobilenet_v2\u001b[38;5;241m.\u001b[39mpreprocess_input(batch_images)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\numpy\\core\\shape_base.py:456\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[0;32m    454\u001b[0m sl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m),) \u001b[38;5;241m*\u001b[39m axis \u001b[38;5;241m+\u001b[39m (_nx\u001b[38;5;241m.\u001b[39mnewaxis,)\n\u001b[0;32m    455\u001b[0m expanded_arrays \u001b[38;5;241m=\u001b[39m [arr[sl] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 36.8 MiB for an array with shape (32, 224, 224, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "# Function to extract features from images using a pre-trained CNN\n",
    "def extract_features(images, batch_size=32):\n",
    "    num_images = len(images)\n",
    "    num_batches = (num_images + batch_size - 1) // batch_size\n",
    "    features = []\n",
    "    \n",
    "    # Replace this with your preferred pre-trained CNN model\n",
    "    pretrained_model = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))\n",
    "    pretrained_model.trainable = False\n",
    "    feature_extractor = tf.keras.Model(inputs=pretrained_model.input, outputs=pretrained_model.layers[-1].output)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_index = i * batch_size\n",
    "        end_index = min((i + 1) * batch_size, num_images)\n",
    "        \n",
    "        # Convert grayscale images to RGB by stacking them along the third axis\n",
    "        batch_images = np.stack((images[start_index:end_index],) * 3, axis=-1)\n",
    "        \n",
    "        # Preprocess images and extract features\n",
    "        preprocessed_images = tf.keras.applications.mobilenet_v2.preprocess_input(batch_images)\n",
    "        batch_features = feature_extractor(preprocessed_images)\n",
    "        features.append(batch_features)\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    \n",
    "    # Reshape features to 2D array\n",
    "    num_samples = features.shape[0]\n",
    "    features_flat = features.reshape(num_samples, -1)\n",
    "    \n",
    "    # Perform incremental PCA to reduce memory usage\n",
    "    ipca = IncrementalPCA(n_components=64, batch_size=batch_size)\n",
    "    reduced_features = ipca.fit_transform(features_flat)\n",
    "    return reduced_features\n",
    "\n",
    "# Extract features from training and test images\n",
    "train_features = extract_features(alz_images_train)\n",
    "test_features = extract_features(alz_images_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m similarities\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Compute image similarities for training and test images\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m train_image_similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_image_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43malz_images_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m test_image_similarity \u001b[38;5;241m=\u001b[39m compute_image_similarity(alz_images_test)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Threshold to determine if two images are similar enough to be connected\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mcompute_image_similarity\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_images):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_images):\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m# Compute cosine similarity between image vectors\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m         similarities[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarities\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1379\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m-> 1379\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n\u001b[0;32m   1381\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1786\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a supported axis\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m axis)\n\u001b[1;32m-> 1786\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe normalize function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1792\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1794\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\sklearn\\utils\\validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m         )\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 899\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\sklearn\\utils\\validation.py:108\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space np.isfinite to prevent\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# false positives from overflow in sum method. The sum is also calculated\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# safely to reduce dtype induced overflows.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m is_float \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_float \u001b[38;5;129;01mand\u001b[39;00m (np\u001b[38;5;241m.\u001b[39misfinite(\u001b[43m_safe_accumulator_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_float:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\sklearn\\utils\\extmath.py:897\u001b[0m, in \u001b[0;36m_safe_accumulator_op\u001b[1;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 897\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to compute image similarity based on cosine similarity\n",
    "def compute_image_similarity(images):\n",
    "    num_images = len(images)\n",
    "    similarities = np.zeros((num_images, num_images))\n",
    "    for i in range(num_images):\n",
    "        for j in range(num_images):\n",
    "            # Compute cosine similarity between image vectors\n",
    "            similarities[i, j] = cosine_similarity(images[i].reshape(1, -1), images[j].reshape(1, -1))[0, 0]\n",
    "    return similarities\n",
    "\n",
    "# Compute image similarities for training and test images\n",
    "train_feature_similarity = compute_feature_similarity(train_features)\n",
    "test_feature_similarity = compute_feature_similarity(test_features)\n",
    "\n",
    "# Threshold to determine if two images are similar enough to be connected\n",
    "similarity_threshold = 0.8\n",
    "\n",
    "# Create graph for training set based on image similarity\n",
    "train_G = nx.Graph()\n",
    "num_train_images = len(alz_images_train)\n",
    "for i in range(num_train_images):\n",
    "    train_G.add_node(i)\n",
    "    for j in range(i + 1, num_train_images):\n",
    "        if train_image_similarity[i, j] >= similarity_threshold:\n",
    "            train_G.add_edge(i, j)\n",
    "\n",
    "# Create graph for test set based on image similarity\n",
    "test_G = nx.Graph()\n",
    "num_test_images = len(alz_images_test)\n",
    "for i in range(num_test_images):\n",
    "    test_G.add_node(i)\n",
    "    for j in range(i + 1, num_test_images):\n",
    "        if test_image_similarity[i, j] >= similarity_threshold:\n",
    "            test_G.add_edge(i, j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to compute similarity between images\n",
    "def compute_similarity(image1, image2):\n",
    "    # Example: compute similarity based on pixel-wise comparison\n",
    "    return np.sum(np.abs(image1 - image2))\n",
    "\n",
    "# Compute adjacency matrix based on image similarities\n",
    "def compute_adjacency_matrix(images):\n",
    "    num_images = len(images)\n",
    "    adjacency_matrix = np.zeros((num_images, num_images))\n",
    "    for i in range(num_images):\n",
    "        for j in range(num_images):\n",
    "            similarity = compute_similarity(images[i], images[j])\n",
    "            adjacency_matrix[i, j] = similarity\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute adjacency matrix for training images and test images\n",
    "train_adj_matrix = compute_adjacency_matrix(alz_images_train)\n",
    "print(\"Shape of adjacency matrix:\", train_adj_matrix.shape)\n",
    "\n",
    "test_adj_matrix = compute_adjacency_matrix(alz_images_test)\n",
    "print(\"Shape of adjacency matrix:\", test_adj_matrix.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
